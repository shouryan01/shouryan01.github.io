{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Whatstats.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGMlxN5pOrab"
      },
      "source": [
        "**IMPORT DATA FILE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVtFBtyxu7OW"
      },
      "source": [
        "#pie chart of chat breakdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEWitmiRNil8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZbJLcr4P-aI"
      },
      "source": [
        "**IMPORT LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6uwaZhOP9wY"
      },
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import re\n",
        "import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dateutil import tz\n",
        "\n",
        "\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPOuZij8FKiV"
      },
      "source": [
        "!pip install emoji --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8Z8sX-hFU4F"
      },
      "source": [
        "from emoji import UNICODE_EMOJI\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqeY6anzPN70",
        "outputId": "ff7ff3f9-362b-4367-dd32-7f3eac753dbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/Data/_chat.txt', 'r', encoding = 'utf-8') as file:\n",
        "    data_lines = [line.strip() for line in file.read().splitlines()]\n",
        "    data = pd.DataFrame(\n",
        "        re.findall(r'\\[(.*?),\\s(.*?)]\\s*([^:]+):\\s*(.*)', '\\n'.join(data_lines)),\n",
        "        columns=['Date', 'Time', 'Author', 'Message']\n",
        "    )\n",
        "    \n",
        "    print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nDAbZY1Co7S"
      },
      "source": [
        "**Process documents**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzMlsrUi_Xvt"
      },
      "source": [
        "documents_list = data['Message'].apply(lambda x: str(re.findall('.*document omitted', x)))\n",
        "documents_list = documents_list.to_frame()\n",
        "documents = documents_list['Message'].unique()\n",
        "documents = [doc for doc in documents if len(doc) > 2]\n",
        "documents = [doc.split(\"\\\\u200\")[0].strip()[2:] for doc in documents]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-sCdurpAO_k"
      },
      "source": [
        "**Big Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6otQziUP2ts"
      },
      "source": [
        "number_of_messages = data.shape[0]\n",
        "number_of_pictures = data[data['Message'] == '‎image omitted'].shape[0]\n",
        "number_of_videos = data[data['Message'] == '‎video omitted'].shape[0]\n",
        "number_of_stickers = data[data['Message'] == '‎sticker omitted'].shape[0]\n",
        "number_of_GIFs = data[data['Message'] == '‎GIF omitted'].shape[0]\n",
        "number_of_documents = len(documents)\n",
        "number_of_deleted_messages = data[data['Message'] == \"‎This message was deleted.\"].shape[0] + data[data['Message'] == '‎You deleted this message.'].shape[0]\n",
        "\n",
        "start_date = datetime.datetime.strptime(data['Date'][0], \"%d/%m/%y\").date()\n",
        "end_date = datetime.datetime.strptime(data['Date'][number_of_messages - 1], \"%d/%m/%y\").date()\n",
        "\n",
        "duration = end_date - start_date\n",
        "duration = duration.days\n",
        "days_chatted = data['Date'].unique().shape[0]\n",
        "print('Chat data start and end dates:', start_date, ':', end_date, '(yyyy-mm-dd)')\n",
        "print('Chat duration is: ', duration, 'days')\n",
        "print('Active days:', days_chatted, '/', duration, 'or {:.2f}%'.format(days_chatted/duration*100) ,'days of duration')\n",
        "\n",
        "print(\"\\nThere are {} participants in this chat: \".format(data['Author'].unique().size))\n",
        "names = [name for name in data['Author'].unique()]\n",
        "for name in names:\n",
        "    print(name)\n",
        "\n",
        "df1 = data[data['Author'] == names[0]]\n",
        "df2 = data[data['Author'] == names[1]]\n",
        "\n",
        "number_text_message = number_of_messages - number_of_pictures - number_of_GIFs - number_of_videos - number_of_stickers - number_of_documents\n",
        "number_text_message\n",
        "\n",
        "print('\\nThey sent a total of {:,} messages:'.format(number_of_messages))\n",
        "print('\\n{:,} of which were text messages, or {:.2f}% of the total {} messages.'.format(number_text_message,number_text_message/number_of_messages*100, number_of_messages))\n",
        "print('{} of which were pictures, or {:.3f}% of the total {} messages.'.format(number_of_pictures,number_of_pictures/number_of_messages*100, number_of_messages))\n",
        "print('{} of which were videos, or {:.3f}% of the total {} messages.'.format(number_of_videos,number_of_videos/number_of_messages*100, number_of_messages))\n",
        "print('{} of which were GIFs, or {:.3f}% of the total {} messages.'.format(number_of_GIFs,number_of_GIFs/number_of_messages*100, number_of_messages))\n",
        "print('{} of which were stickers, or {:.3f}% of the total {} messages.'.format(number_of_stickers,number_of_stickers/number_of_messages*100, number_of_messages))\n",
        "print('{} of which were documents, or {:.3f}% of the total {} messages.'.format(number_of_documents,number_of_documents/number_of_messages*100, number_of_messages))\n",
        "print('\\n===The documents were:===')\n",
        "for doc in documents:\n",
        "    print(doc)\n",
        "\n",
        "print('\\nA total of {} messages sent were deleted, or {:.2f}% of the total {} messages.'.format(number_of_deleted_messages, number_of_deleted_messages/number_of_messages * 100, number_of_messages))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECkuF94v9Yuj"
      },
      "source": [
        "**Calculate number of words sent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv2RcMxg8oZi"
      },
      "source": [
        "data['Number of Words'] = data['Message'].apply(lambda x: len(x.split()))\n",
        "number_of_words = data['Number of Words'].sum()\n",
        "\n",
        "document_words = [len(doc.split()) for doc in documents]\n",
        "document_words = sum(document_words)\n",
        "\n",
        "number_of_words = number_of_words - (number_of_pictures*2) - (number_of_GIFs*2) - (number_of_videos*2) - (number_of_stickers*2) - (number_of_documents*2) - document_words\n",
        "\n",
        "print('They sent a total of {:,} words, for an average of {:.2f} words per (text only) message.'.format(number_of_words, number_of_words/number_text_message))\n",
        "\n",
        "\n",
        "most_common_messages = pd.DataFrame(data.Message.value_counts())\n",
        "most_common_messages.drop(['‎This message was deleted.','‎image omitted','‎You deleted this message.', '‎video omitted', '‎GIF omitted'], inplace=True)\n",
        "\n",
        "print(\"\\nThe 50 most common messages were:\")\n",
        "most_common_messages.head(50) #this is most common message"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmVQ5lou1di3"
      },
      "source": [
        "words = Counter()\n",
        "data['Message'].str.lower().str.split().apply(words.update)\n",
        "\n",
        "print(\"Top 100 most commonly used words:\")\n",
        "words.most_common(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c9L48GCRm-J"
      },
      "source": [
        "**Get Emojis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrnYkEVNRmRA",
        "outputId": "4dcddc62-16ff-400a-910b-bb76665dc254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def get_emojis(string):\n",
        "    return ''.join([ch for ch in string if ch in UNICODE_EMOJI])\n",
        "\n",
        "\n",
        "emojis = Counter(data['Message'].apply(lambda x: get_emojis(x)).sum())\n",
        "emojis = {k: v for k,v in sorted(emojis.items(), key=lambda item: item[1], reverse=True)}\n",
        "print('There are {} unique emojis used in this chat.'.format(len(emojis)))\n",
        "print('A total of {} emojis were used.'.format(sum(emojis.values())))\n",
        "\n",
        "print('These are all the emojis used, sorted in reverse ascending order:\\n')\n",
        "for emoji,number in emojis.items():\n",
        "    print(emoji, number)"
      ],
      "execution_count": 760,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 178 unique emojis used in this chat.\n",
            "A total of 9220 emojis were used.\n",
            "These are all the emojis used, sorted in reverse ascending order:\n",
            "\n",
            "😂 7548\n",
            "😭 234\n",
            "♀ 155\n",
            "🤦 122\n",
            "🏼 102\n",
            "👋 84\n",
            "🏻 77\n",
            "😒 59\n",
            "🥺 53\n",
            "😴 52\n",
            "🤷 39\n",
            "🤪 38\n",
            "❤ 34\n",
            "😊 33\n",
            "😅 30\n",
            "😢 29\n",
            "😞 25\n",
            "😑 21\n",
            "👏 19\n",
            "😓 18\n",
            "☀ 17\n",
            "😨 16\n",
            "♂ 15\n",
            "🎉 15\n",
            "😤 13\n",
            "☺ 13\n",
            "🎊 13\n",
            "😁 12\n",
            "😬 12\n",
            "🤣 10\n",
            "😈 10\n",
            "👍 10\n",
            "🍪 9\n",
            "😖 8\n",
            "🤮 8\n",
            "👌 7\n",
            "😍 7\n",
            "🚬 7\n",
            "😏 7\n",
            "😄 6\n",
            "💤 6\n",
            "😐 6\n",
            "😔 6\n",
            "🤎 5\n",
            "🙋 5\n",
            "💔 5\n",
            "😪 4\n",
            "🙄 4\n",
            "😡 4\n",
            "😎 4\n",
            "💓 4\n",
            "🙈 4\n",
            "🇺 4\n",
            "🇸 4\n",
            "😇 3\n",
            "😌 3\n",
            "😚 3\n",
            "😘 3\n",
            "🐣 3\n",
            "🥰 3\n",
            "😠 3\n",
            "⬆ 3\n",
            "‼ 3\n",
            "🥳 3\n",
            "🎈 3\n",
            "🍡 2\n",
            "💰 2\n",
            "🦠 2\n",
            "🍳 2\n",
            "🙃 2\n",
            "🥴 2\n",
            "😉 2\n",
            "✨ 2\n",
            "🙇 2\n",
            "🕛 2\n",
            "🦥 2\n",
            "🍯 2\n",
            "♾ 2\n",
            "😶 2\n",
            "😣 2\n",
            "🤝 2\n",
            "🤭 2\n",
            "💜 2\n",
            "😃 2\n",
            "😱 2\n",
            "🤐 2\n",
            "☹ 2\n",
            "👎 1\n",
            "🧀 1\n",
            "🕉 1\n",
            "🍰 1\n",
            "🇨 1\n",
            "🇦 1\n",
            "🦷 1\n",
            "👐 1\n",
            "🍹 1\n",
            "🧠 1\n",
            "⭐ 1\n",
            "👀 1\n",
            "🥨 1\n",
            "🐊 1\n",
            "🙁 1\n",
            "😗 1\n",
            "😙 1\n",
            "🔥 1\n",
            "🧐 1\n",
            "😮 1\n",
            "🌬 1\n",
            "☃ 1\n",
            "🙅 1\n",
            "😧 1\n",
            "💦 1\n",
            "🔫 1\n",
            "☎ 1\n",
            "🍾 1\n",
            "🕧 1\n",
            "🕐 1\n",
            "🕜 1\n",
            "🕑 1\n",
            "🕝 1\n",
            "🕒 1\n",
            "🕞 1\n",
            "🕓 1\n",
            "🕟 1\n",
            "🕔 1\n",
            "🕠 1\n",
            "🕕 1\n",
            "🕡 1\n",
            "🕖 1\n",
            "🕢 1\n",
            "🕗 1\n",
            "🕣 1\n",
            "🕘 1\n",
            "🕤 1\n",
            "🕙 1\n",
            "🕥 1\n",
            "🕚 1\n",
            "🕦 1\n",
            "🤗 1\n",
            "🏫 1\n",
            "🛑 1\n",
            "🚀 1\n",
            "🇪 1\n",
            "🇬 1\n",
            "🗼 1\n",
            "🦄 1\n",
            "🐒 1\n",
            "🚿 1\n",
            "🌊 1\n",
            "🤖 1\n",
            "🧟 1\n",
            "🐦 1\n",
            "🎨 1\n",
            "🗺 1\n",
            "👩 1\n",
            "🦰 1\n",
            "🍂 1\n",
            "☕ 1\n",
            "❇ 1\n",
            "🧸 1\n",
            "🥶 1\n",
            "🦋 1\n",
            "🦚 1\n",
            "❗ 1\n",
            "🦅 1\n",
            "😵 1\n",
            "🧇 1\n",
            "🥱 1\n",
            "🦧 1\n",
            "😫 1\n",
            "🤢 1\n",
            "🥜 1\n",
            "😩 1\n",
            "😋 1\n",
            "🎩 1\n",
            "📺 1\n",
            "🤔 1\n",
            "🤤 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LDr82FksfXU"
      },
      "source": [
        "data_as_string = data['Message'].str\n",
        "\n",
        "avg_char = data_as_string.len().mean()\n",
        "characters = data_as_string.len().sum() - 77 #fix \n",
        "\n",
        "doc_lengths = [len(doc) for doc in documents]\n",
        "chars_in_docs = 0\n",
        "for i in doc_lengths:\n",
        "    chars_in_docs += i\n",
        "characters -= chars_in_docs\n",
        "\n",
        "print('A total of {:,} characters were sent'.format(characters))\n",
        "print('Each message sent had an average of {:.2f} characters'.format(avg_char))\n",
        "\n",
        "def get_chars(string):\n",
        "    return ''.join([ch for ch in string if ch not in UNICODE_EMOJI])\n",
        "\n",
        "letters = Counter(data['Message'].apply(lambda x: get_chars(x)).sum())\n",
        "letters = {k: v for k,v in sorted(letters.items(), key=lambda item: item[1], reverse=True)}\n",
        "print('There are {} unique characters used in this chat.'.format(len(letters)))\n",
        "\n",
        "print('These are all the characters used, sorted in reverse ascending order:\\n')\n",
        "for emoji,number in letters.items():\n",
        "    print(emoji, number)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2OKNQw8M4zv"
      },
      "source": [
        "**Person 1 Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsr48H2ed3d1"
      },
      "source": [
        "documents_list_df1 = df1['Message'].apply(lambda x: str(re.findall('.*document omitted', x)))\n",
        "documents_list_df1 = documents_list_df1.to_frame()\n",
        "documents_df1 = documents_list_df1['Message'].unique()\n",
        "documents_df1 = [doc for doc in documents_df1 if len(doc) > 2]\n",
        "documents_df1 = [doc.split(\"\\\\u200\")[0].strip()[2:] for doc in documents_df1]\n",
        "\n",
        "number_of_messages_df1 = df1.shape[0]\n",
        "number_of_pictures_df1 = df1[df1['Message'] == '‎image omitted'].shape[0]\n",
        "number_of_videos_df1 = df1[df1['Message'] == '‎video omitted'].shape[0]\n",
        "number_of_stickers_df1 = df1[df1['Message'] == '‎sticker omitted'].shape[0]\n",
        "number_of_GIFs_df1 = df1[df1['Message'] == '‎GIF omitted'].shape[0]\n",
        "number_of_documents_df1 = len(documents_df1)\n",
        "number_of_deleted_messages_df1 = df1[df1['Message'] == '‎This message was deleted.'].shape[0] +  df1[df1['Message'] == '‎You deleted this message.'].shape[0]\n",
        "\n",
        "number_text_message_df1 = number_of_messages_df1 - number_of_pictures_df1 - number_of_GIFs_df1 - number_of_videos_df1 - number_of_stickers_df1 - number_of_documents_df1\n",
        "\n",
        "print(names[0], 'has sent: {} messages, or {:.2f}% of the total {} messages.'.format(number_of_messages_df1, number_of_messages_df1/number_of_messages*100, data.shape[0]))\n",
        "print('\\n{:,} of which were text messages, or {:.2f}% of the total {} text messages.'.format(number_text_message_df1, number_of_messages_df1/number_text_message*100, number_text_message))\n",
        "print('{} of which were pictures, or {:.2f}% of the total {} pictures.'.format(number_of_pictures_df1, number_of_pictures_df1/number_of_pictures*100, number_of_pictures))\n",
        "\n",
        "print('{} of which were videos, or {:.2f}% of the total {} videos.'.format(number_of_videos_df1, number_of_videos_df1/number_of_videos*100, number_of_videos))\n",
        "print('{} of which were GIFs, or {:.2f}% of the total {} GIFs.'.format(number_of_GIFs_df1, number_of_GIFs_df1/number_of_GIFs*100, number_of_GIFs))\n",
        "print('{} of which were stickers, or {:.2f}% of the total {} stickers.'.format(number_of_stickers_df1, number_of_stickers_df1/number_of_stickers*100, number_of_stickers))\n",
        "print('{} of which were documents, or {:.2f}% of the total {} documents.'.format(number_of_documents_df1, number_of_documents_df1/number_of_documents*100, number_of_documents))\n",
        "print('\\n===The documents were:===')\n",
        "for doc in documents_df1:\n",
        "    print(doc)\n",
        "print(\"\")\n",
        "print(names[0],'deleted {} messages, or {:.2f}% of the total {} deleted messages.'.format(number_of_deleted_messages_df1, number_of_deleted_messages_df1/number_of_deleted_messages * 100, number_of_deleted_messages))\n",
        "\n",
        "number_of_words_df1 = df1['Number of Words'].sum()\n",
        "\n",
        "document_words_df1 = [len(doc.split()) for doc in documents_df1]\n",
        "document_words_df1 = sum(document_words_df1)\n",
        "\n",
        "number_of_words_df1 = number_of_words_df1 - (number_of_pictures_df1*2) - (number_of_GIFs_df1*2) - (number_of_videos_df1*2) - (number_of_stickers_df1*2) - (number_of_documents_df1*2) - document_words_df1\n",
        "\n",
        "print(\"\")\n",
        "print(names[0], 'has sent: {:,} words, or {:.2f}% of the total {} words.'.format(number_of_words_df1, number_of_words_df1/number_of_words*100, number_of_words))\n",
        "print(names[0], 'sends about {:.2f} words per message.'.format(number_of_words_df1/number_text_message_df1))\n",
        "\n",
        "data_as_string_df1 = df1['Message'].str\n",
        "\n",
        "avg_char_df1 = data_as_string_df1.len().mean()\n",
        "characters_df1 = data_as_string_df1.len().sum() - 77 #fix\n",
        "\n",
        "doc_lengths_df1 = [len(doc) for doc in documents_df1]\n",
        "chars_in_docs_df1 = 0\n",
        "for i in doc_lengths_df1:\n",
        "    chars_in_docs_df1 += i\n",
        "characters_df1 -= chars_in_docs_df1\n",
        "\n",
        "print(\"\")\n",
        "print(names[0],'sent a total of {:,} characters, or {:.2f}% of the total {} characters.'.format(characters_df1, characters_df1/characters*100, characters))\n",
        "print('Each message sent had an average of {:.2f} characters'.format(avg_char_df1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQj3jIElBJ2X"
      },
      "source": [
        "most_common_messages_df1 = pd.DataFrame(df1.Message.value_counts())\n",
        "most_common_messages_df1.drop(['‎This message was deleted.','‎image omitted', '‎video omitted', '‎GIF omitted', '‎sticker omitted'], inplace=True)\n",
        "\n",
        "print(\"\\nThe 25 most common messages for {} were:\".format(names[0]))\n",
        "most_common_messages_df1.head(25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tog3yK-Q2Sbj"
      },
      "source": [
        "words_df1 = Counter()\n",
        "df1['Message'].str.lower().str.split().apply(words_df1.update)\n",
        "\n",
        "print(\"Top 50 most commonly used words for {}:\".format(names[0]))\n",
        "words_df1.most_common(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d88BQf7ZEbZu"
      },
      "source": [
        "emojis_df1 = Counter(df1['Message'].apply(lambda x: get_emojis(x)).sum())\n",
        "emojis_df1 = {k: v for k,v in sorted(emojis_df1.items(), key=lambda item: item[1], reverse=True)}\n",
        "print(names[0],'used {} unique emojis in this chat.'.format(len(emojis_df1)))\n",
        "print(names[0], 'used a total of {} emojis'.format(sum(emojis_df1.values())))\n",
        "\n",
        "print('These are all the emojis used, sorted in reverse ascending order:\\n')\n",
        "for emoji,number in emojis_df1.items():\n",
        "    print(emoji, number)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8JOiGGeM1ua"
      },
      "source": [
        "**Person 2 Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im8PVW8Nga-3"
      },
      "source": [
        "documents_list_df2 = df2['Message'].apply(lambda x: str(re.findall('.*document omitted', x)))\n",
        "documents_list_df2 = documents_list_df2.to_frame()\n",
        "documents_df2 = documents_list_df2['Message'].unique()\n",
        "documents_df2 = [doc for doc in documents_df2 if len(doc) > 2]\n",
        "documents_df2 = [doc.split(\"\\\\u200\")[0].strip()[2:] for doc in documents_df2]\n",
        "\n",
        "number_of_messages_df2 = df2.shape[0]\n",
        "number_of_pictures_df2 = df2[df2['Message'] == '‎image omitted'].shape[0]\n",
        "number_of_videos_df2 = df2[df2['Message'] == '‎video omitted'].shape[0]\n",
        "number_of_stickers_df2 = df2[df2['Message'] == '‎sticker omitted'].shape[0]\n",
        "number_of_GIFs_df2 = df2[df2['Message'] == '‎GIF omitted'].shape[0]\n",
        "number_of_documents_df2 = len(documents_df2)\n",
        "number_of_deleted_messages_df2 = df2[df2['Message'] == '‎This message was deleted.'].shape[0] + df2[df2['Message'] == '‎You deleted this message.'].shape[0]\n",
        "\n",
        "\n",
        "number_text_message_df2 = number_of_messages_df2 - number_of_pictures_df2 - number_of_GIFs_df2 - number_of_videos_df2 - number_of_stickers_df2 - number_of_documents_df2\n",
        "\n",
        "print(names[1], 'has sent: {} messages, or {:.2f}% of the total {} messages.'.format(number_of_messages_df2, number_of_messages_df2/number_of_messages*100, data.shape[0]))\n",
        "print('\\n{:,} of which were text messages, or {:.2f}% of the total {} text messages.'.format(number_text_message_df2, number_of_messages_df2/number_text_message*100, number_text_message))\n",
        "print('{} of which were pictures, or {:.2f}% of the total {} pictures.'.format(number_of_pictures_df2, number_of_pictures_df2/number_of_pictures*100, number_of_pictures))\n",
        "\n",
        "print('{} of which were videos, or {:.2f}% of the total {} videos.'.format(number_of_videos_df2, number_of_videos_df2/number_of_videos*100, number_of_videos))\n",
        "print('{} of which were GIFs, or {:.2f}% of the total {} GIFs.'.format(number_of_GIFs_df2, number_of_GIFs_df2/number_of_GIFs*100, number_of_GIFs))\n",
        "print('{} of which were stickers, or {:.2f}% of the total {} stickers.'.format(number_of_stickers_df2, number_of_stickers_df2/number_of_stickers*100, number_of_stickers))\n",
        "print('{} of which were documents, or {:.2f}% of the total {} documents.'.format(number_of_documents_df2, number_of_documents_df2/number_of_documents*100, number_of_documents))\n",
        "print('\\n===The documents were:===')\n",
        "for doc in documents_df2:\n",
        "    print(doc)\n",
        "print(\"\")\n",
        "print(names[1],'deleted {} messages, or {:.2f}% of the total {} deleted messages.'.format(number_of_deleted_messages_df2, number_of_deleted_messages_df2/number_of_deleted_messages * 100, number_of_deleted_messages))\n",
        "\n",
        "number_of_words_df2 = df2['Number of Words'].sum()\n",
        "\n",
        "document_words_df2 = [len(doc.split()) for doc in documents_df2]\n",
        "document_words_df2 = sum(document_words_df2)\n",
        "\n",
        "number_of_words_df2 = number_of_words_df2 - (number_of_pictures_df2*2) - (number_of_GIFs_df2*2) - (number_of_videos_df2*2) - (number_of_stickers_df2*2) - (number_of_documents_df2*2) - document_words_df2\n",
        "\n",
        "print(\"\")\n",
        "print(names[1], 'has sent: {:,} words, or {:.2f}% of the total {} words.'.format(number_of_words_df2, number_of_words_df2/number_of_words*100, number_of_words))\n",
        "print(names[1], 'sends about {:.2f} words per message.'.format(number_of_words_df2/number_text_message_df2))\n",
        "\n",
        "data_as_string_df2 = df2['Message'].str\n",
        "\n",
        "avg_char_df2 = data_as_string_df2.len().mean()\n",
        "characters_df2 = data_as_string_df2.len().sum() - 77 #fix\n",
        "\n",
        "doc_lengths_df2 = [len(doc) for doc in documents_df2]\n",
        "chars_in_docs_df2 = 0\n",
        "for i in doc_lengths_df2:\n",
        "    chars_in_docs_df2 += i\n",
        "characters_df2 -= chars_in_docs_df2\n",
        "\n",
        "print(\"\")\n",
        "print(names[1],'sent a total of {:,} characters, or {:.2f}% of the total {} characters.'.format(characters_df2, characters_df2/characters*100, characters))\n",
        "print('Each message sent had an average of {:.2f} characters'.format(avg_char_df2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiQ12UkDCOM4"
      },
      "source": [
        "most_common_messages_df2 = pd.DataFrame(df2.Message.value_counts())\n",
        "most_common_messages_df2.drop(['‎You deleted this message.','‎image omitted', '‎video omitted', '‎GIF omitted', '‎sticker omitted'], inplace=True)\n",
        "\n",
        "print(\"\\nThe 25 most common messages for {} were:\".format(names[1]))\n",
        "most_common_messages_df2.head(25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZav2sPu2w8w"
      },
      "source": [
        "words_df2 = Counter()\n",
        "df2['Message'].str.lower().str.split().apply(words_df2.update)\n",
        "\n",
        "print(\"Top 50 most commonly used words for {}:\".format(names[1]))\n",
        "words_df2.most_common(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Sd5dO1M9i3"
      },
      "source": [
        "emojis_df2 = Counter(df2['Message'].apply(lambda x: get_emojis(x)).sum())\n",
        "emojis_df2 = {k: v for k,v in sorted(emojis_df2.items(), key=lambda item: item[1], reverse=True)}\n",
        "print(names[1],'used {} unique emojis in this chat.'.format(len(emojis_df2)))\n",
        "print(names[1], 'used a total of {} emojis'.format(sum(emojis_df2.values())))\n",
        "\n",
        "print('These are all the emojis used, sorted in reverse ascending order:\\n')\n",
        "for emoji,number in emojis_df2.items():\n",
        "    print(emoji, number)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDUEehSPwNfu"
      },
      "source": [
        "**VISUALIZATIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV0dCtbG73Gt"
      },
      "source": [
        "data['Message Length'] = data['Message'].str.len()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxJ-On1xwNBW"
      },
      "source": [
        "data['Date'] = [datetime.datetime.strptime(date, \"%d/%m/%y\").date() for date in data['Date']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nq_oCkc3yiX"
      },
      "source": [
        "data['Time'] = [datetime.datetime.strptime(time, \"%I:%M:%S %p\").time() for time in data['Time']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmvo6ycw4rGK"
      },
      "source": [
        "data.groupby(['Date']).size().plot(figsize=(25,6), title='Number Of Messages Each Day')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lWlfUfGQL2r"
      },
      "source": [
        "min_messages_date = data.groupby(['Date']).size().idxmin()\n",
        "min_messages = data.groupby(['Date']).size().min()\n",
        "print('On',min_messages_date,'was the lowest number of messages sent, which was:',min_messages)\n",
        "\n",
        "max_messages_date = data.groupby(['Date']).size().idxmax()\n",
        "max_messages = data.groupby(['Date']).size().max()\n",
        "print('On',max_messages_date,'was the highest number of messages sent, which was:',max_messages)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwSQlZp7F8pX"
      },
      "source": [
        "data.groupby('Date')['Number of Words'].sum().plot(figsize=(25,6), title='Total Number Of Words per Day')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ocQbaxJ56Bb"
      },
      "source": [
        "data.groupby('Date')['Number of Words'].mean().plot(figsize=(25,6), title='Average Number Of Words per Message per Day')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlqYHPWKGIMt"
      },
      "source": [
        "data.groupby('Date')['Message Length'].sum().plot(figsize=(25,6), title='Total Number Of Characters per Day')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnnZzGh88HbD"
      },
      "source": [
        "data.groupby('Date')['Message Length'].mean().plot(figsize=(25,6), title=\"Average Number of Characters per Message per Day\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQhJdzquQYDv"
      },
      "source": [
        "data['Reply Time'] = 0\n",
        "for i in range(len(data)-2):\n",
        "    data['Reply Time'][i+1] = datetime.datetime.combine(data['Date'][i+1],data['Time'][i+1]) - datetime.datetime.combine(data['Date'][i],data['Time'][i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUj0d8ElIA_9"
      },
      "source": [
        "data.groupby(['Date','Author']).count()['Message'].unstack().plot(figsize=(25,6), title=names[0]+' vs '+names[1]+' in number of messages sent per Day')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft_aoyAXMBIZ"
      },
      "source": [
        "data.groupby(['Date','Author'])['Number of Words'].sum().unstack().plot(figsize=(25,6), title=names[0]+' vs '+names[1]+' in number of words sent per Day')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tETMNx88MzuT"
      },
      "source": [
        "data.groupby(['Date','Author'])['Message Length'].mean().unstack().plot(figsize=(25,6), title=names[0]+' vs '+names[1]+' in average message length per Day')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NV7nfSONq7w"
      },
      "source": [
        "data['Reply Time'][0] = data['Reply Time'][1]\n",
        "data['Reply Time'][len(data)-1] = data['Reply Time'][1]\n",
        "data['Reply Time'] = data['Reply Time'].apply(lambda x: x.total_seconds())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mtH1rjzROZm"
      },
      "source": [
        "data['Convo ID'] = (data['Reply Time'] > 1200).cumsum().fillna(0).astype(int) + 1\n",
        "\n",
        "print('There are '+str(data['Convo ID'].max())+' unique conversations.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m01jqnZsTIe1"
      },
      "source": [
        "data.groupby(['Convo ID']).count()['Message'].plot(figsize=(25,6),title=\"Number of messages per conversation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTKUmAEyTxPI"
      },
      "source": [
        "data.groupby(['Convo ID'])['Number of Words'].mean().plot(figsize=(25,6),title=\"Average Number of words per message per conversation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgIKFqaTUxfd"
      },
      "source": [
        "data.groupby(['Convo ID'])['Message Length'].mean().plot(figsize=(25,6),title=\"Average Length of Message per conversation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qsixzJgVxGT"
      },
      "source": [
        "xc = data[data['Convo ID'].between(200,250)]\n",
        "record = xc[xc['Message Length'] == 2887]"
      ],
      "execution_count": 571,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v88M_AoaYGJS"
      },
      "source": [
        "print('This is that super long ass message:')\n",
        "record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWvSPgSbXiO8"
      },
      "source": [
        "print(\"Your reply to all that effort :(\")\n",
        "xc[xc['Convo ID'] == 230].iloc[0].Message"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdMSLREfvoY8",
        "outputId": "3e8cb4fa-e34a-4229-d024-de0a33a328c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('Average reply time for '+names[0]+' is {:.2f}'.format(data[data['Author'] == names[0]]['Reply Time'].mean()))\n",
        "print('Average reply time for '+names[1]+' is {:.2f}'.format(data[data['Author'] == names[1]]['Reply Time'].mean()))\n",
        "\n",
        "print('\\n^^ This is not representative of the TRUE reply time, as it depends on how quickly replies are sent after a convo is over')"
      ],
      "execution_count": 584,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average reply time for Shaw 🐣 is 579.51\n",
            "Average reply time for Preetika Sastry is 493.79\n",
            "\n",
            "^^ This is not representative of the TRUE reply time, as it depends on how quickly replies are sent after a convo is over\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbxJLdllYTvD"
      },
      "source": [
        "data.groupby('Convo ID')['Reply Time'].mean().div(1000).plot(figsize=(25,6), title='Average Reply Time in Seconds per Converation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVsfc6i_vHMw"
      },
      "source": [
        "data.groupby(['Convo ID','Author'])['Reply Time'].mean().div(1000).unstack().plot(figsize=(25,6), title='Average Reply Time in Seconds per Converation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUQdc9kUeAxr"
      },
      "source": [
        "data['Day of Week'] = data.Date.apply(lambda x: x.weekday())\n"
      ],
      "execution_count": 587,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwAHO1j0goK2"
      },
      "source": [
        "data.sort_values(by=['Day of Week']).groupby('Day of Week').count()['Message'].plot(figsize=(25,6), ylabel='Number of Messages', title='Day of Week vs Number of Messages').set_xticklabels(['','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VycZ8hEiAER"
      },
      "source": [
        "data['Time2'] = data.Time.apply(lambda x: x.replace(second=0))\n",
        "data['Time3'] = data.Time.apply(lambda x: x.replace(minute=0, second=0))"
      ],
      "execution_count": 589,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U3IJCgWkbm0"
      },
      "source": [
        "data.groupby(['Time2']).count()['Message'].plot(figsize=(25,6), ylabel='Number of Messages', title='Time of Day (Minutes) vs Number of Messages')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4mD70mZuNfX"
      },
      "source": [
        "data.groupby(['Time3']).count()['Message'].plot(figsize=(25,6), ylabel='Number of Messages', title='Time of Day (Hours) vs Number of Messages')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJD_-kfzHbJs"
      },
      "source": [
        "print(names[0]+' has started {} conversations'.format(data.groupby('Convo ID').first()['Author'].value_counts()[0]))\n",
        "print(names[1]+' has started {} conversations'.format(data.groupby('Convo ID').first()['Author'].value_counts()[1]))\n",
        "print(\"\")\n",
        "print(names[0]+' said \"bye\" last in {} conversations'.format(data.groupby('Convo ID').last()['Author'].value_counts()[0]))\n",
        "print(names[1]+' said \"bye\" last in {} conversations'.format(data.groupby('Convo ID').last()['Author'].value_counts()[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BrvSRyeJ1eE"
      },
      "source": [
        "convo_starts = data.groupby('Convo ID').first()\n",
        "convo_ends = data.groupby('Convo ID').last()\n",
        "convo_dur = pd.concat([convo_starts,convo_ends]).drop_duplicates(keep=False).sort_values(['Date','Time']).reset_index()\n",
        "\n",
        "\n",
        "convo_dur['Convo Time'] = 0\n",
        "for i in range(len(convo_dur)-2):\n",
        "    convo_dur['Convo Time'][i+1] = datetime.datetime.combine(convo_dur['Date'][i+1],convo_dur['Time'][i+1]) - datetime.datetime.combine(convo_dur['Date'][i],convo_dur['Time'][i])\n",
        "convo_dur.drop([len(convo_dur)-1,len(convo_dur)-2], inplace=True)\n",
        "\n",
        "convo_dur = convo_dur.iloc[1::2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOBVpwh-SE4t",
        "outputId": "0f32fa0e-eb28-4419-e193-46fadd65dac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_time = convo_dur['Convo Time'].max().seconds\n",
        "print('Longest time chatted is: {}h {}m {}s'.format(max_time//3600,(max_time%3600)//60, max_time%60))"
      ],
      "execution_count": 726,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longest time chatted is: 4h 19m 57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEBhimXsXqB7"
      },
      "source": [
        "avg_chat_length = sum(convo_dur['Convo Time'], datetime.timedelta(0)) / len(convo_dur['Convo Time'])\n",
        "print('Average chat length is: {}h {}m {}s'.format(avg_chat_length.seconds//3600,(avg_chat_length.seconds%3600)//60, avg_chat_length.seconds%60))\n",
        "\n",
        "print(\"\\n^^ This is a naive calculation, and not truly representative of the true mean\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TlFs803Mik4"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ngw_IIGPn95"
      },
      "source": [
        "drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}