{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Whatstats.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGMlxN5pOrab"
      },
      "source": [
        "**IMPORT DATA FILE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVtFBtyxu7OW"
      },
      "source": [
        "#pie chart of chat breakdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEWitmiRNil8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZbJLcr4P-aI"
      },
      "source": [
        "**IMPORT LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6uwaZhOP9wY"
      },
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import re\n",
        "import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from dateutil import tz\n",
        "\n",
        "\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPOuZij8FKiV"
      },
      "source": [
        "!pip install emoji --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8Z8sX-hFU4F"
      },
      "source": [
        "from emoji import UNICODE_EMOJI\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqeY6anzPN70",
        "outputId": "ff7ff3f9-362b-4367-dd32-7f3eac753dbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/Data/_chat.txt', 'r', encoding = 'utf-8') as file:\n",
        "    data_lines = [line.strip() for line in file.read().splitlines()]\n",
        "    data = pd.DataFrame(\n",
        "        re.findall(r'\\[(.*?),\\s(.*?)]\\s*([^:]+):\\s*(.*)', '\\n'.join(data_lines)),\n",
        "        columns=['Date', 'Time', 'Author', 'Message']\n",
        "    )\n",
        "    \n",
        "    print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nDAbZY1Co7S"
      },
      "source": [
        "**Process documents**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzMlsrUi_Xvt"
      },
      "source": [
        "documents_list = data['Message'].apply(lambda x: str(re.findall('.*document omitted', x)))\n",
        "documents_list = documents_list.to_frame()\n",
        "documents = documents_list['Message'].unique()\n",
        "documents = [doc for doc in documents if len(doc) > 2]\n",
        "documents = [doc.split(\"\\\\u200\")[0].strip()[2:] for doc in documents]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-sCdurpAO_k"
      },
      "source": [
        "**Big Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6otQziUP2ts"
      },
      "source": [
        "number_of_messages = data.shape[0]\n",
        "number_of_pictures = data[data['Message'] == '‚Äéimage omitted'].shape[0]\n",
        "number_of_videos = data[data['Message'] == '‚Äévideo omitted'].shape[0]\n",
        "number_of_stickers = data[data['Message'] == '‚Äésticker omitted'].shape[0]\n",
        "number_of_GIFs = data[data['Message'] == '‚ÄéGIF omitted'].shape[0]\n",
        "number_of_documents = len(documents)\n",
        "number_of_deleted_messages = data[data['Message'] == \"‚ÄéThis message was deleted.\"].shape[0] + data[data['Message'] == '‚ÄéYou deleted this message.'].shape[0]\n",
        "\n",
        "start_date = datetime.datetime.strptime(data['Date'][0], \"%d/%m/%y\").date()\n",
        "end_date = datetime.datetime.strptime(data['Date'][number_of_messages - 1], \"%d/%m/%y\").date()\n",
        "\n",
        "duration = end_date - start_date\n",
        "duration = duration.days\n",
        "days_chatted = data['Date'].unique().shape[0]\n",
        "print('Chat data start and end dates:', start_date, ':', end_date, '(yyyy-mm-dd)')\n",
        "print('Chat duration is: ', duration, 'days')\n",
        "print('Active days:', days_chatted, '/', duration, 'or {:.2f}%'.format(days_chatted/duration*100) ,'days of duration')\n",
        "\n",
        "print(\"\\nThere are {} participants in this chat: \".format(data['Author'].unique().size))\n",
        "names = [name for name in data['Author'].unique()]\n",
        "for name in names:\n",
        "    print(name)\n",
        "\n",
        "df1 = data[data['Author'] == names[0]]\n",
        "df2 = data[data['Author'] == names[1]]\n",
        "\n",
        "number_text_message = number_of_messages - number_of_pictures - number_of_GIFs - number_of_videos - number_of_stickers - number_of_documents\n",
        "number_text_message\n",
        "\n",
        "print('\\nThey sent a total of {:,} messages:'.format(number_of_messages))\n",
        "print('\\n{:,} of which were text messages, or {:.2f}% of the total {} messages.'.format(number_text_message,number_text_message/number_of_messages*100, number_of_messages))\n",
        "print('{} of which were pictures, or {:.3f}% of the total {} messages.'.format(number_of_pictures,number_of_pictures/number_of_messages*100, number_of_messages))\n",
        "print('{} of which were videos, or {:.3f}% of the total {} messages.'.format(number_of_videos,number_of_videos/number_of_messages*100, number_of_messages))\n",
        "print('{} of which were GIFs, or {:.3f}% of the total {} messages.'.format(number_of_GIFs,number_of_GIFs/number_of_messages*100, number_of_messages))\n",
        "print('{} of which were stickers, or {:.3f}% of the total {} messages.'.format(number_of_stickers,number_of_stickers/number_of_messages*100, number_of_messages))\n",
        "print('{} of which were documents, or {:.3f}% of the total {} messages.'.format(number_of_documents,number_of_documents/number_of_messages*100, number_of_messages))\n",
        "print('\\n===The documents were:===')\n",
        "for doc in documents:\n",
        "    print(doc)\n",
        "\n",
        "print('\\nA total of {} messages sent were deleted, or {:.2f}% of the total {} messages.'.format(number_of_deleted_messages, number_of_deleted_messages/number_of_messages * 100, number_of_messages))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECkuF94v9Yuj"
      },
      "source": [
        "**Calculate number of words sent**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv2RcMxg8oZi"
      },
      "source": [
        "data['Number of Words'] = data['Message'].apply(lambda x: len(x.split()))\n",
        "number_of_words = data['Number of Words'].sum()\n",
        "\n",
        "document_words = [len(doc.split()) for doc in documents]\n",
        "document_words = sum(document_words)\n",
        "\n",
        "number_of_words = number_of_words - (number_of_pictures*2) - (number_of_GIFs*2) - (number_of_videos*2) - (number_of_stickers*2) - (number_of_documents*2) - document_words\n",
        "\n",
        "print('They sent a total of {:,} words, for an average of {:.2f} words per (text only) message.'.format(number_of_words, number_of_words/number_text_message))\n",
        "\n",
        "\n",
        "most_common_messages = pd.DataFrame(data.Message.value_counts())\n",
        "most_common_messages.drop(['‚ÄéThis message was deleted.','‚Äéimage omitted','‚ÄéYou deleted this message.', '‚Äévideo omitted', '‚ÄéGIF omitted'], inplace=True)\n",
        "\n",
        "print(\"\\nThe 50 most common messages were:\")\n",
        "most_common_messages.head(50) #this is most common message"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmVQ5lou1di3"
      },
      "source": [
        "words = Counter()\n",
        "data['Message'].str.lower().str.split().apply(words.update)\n",
        "\n",
        "print(\"Top 100 most commonly used words:\")\n",
        "words.most_common(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c9L48GCRm-J"
      },
      "source": [
        "**Get Emojis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrnYkEVNRmRA",
        "outputId": "4dcddc62-16ff-400a-910b-bb76665dc254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def get_emojis(string):\n",
        "    return ''.join([ch for ch in string if ch in UNICODE_EMOJI])\n",
        "\n",
        "\n",
        "emojis = Counter(data['Message'].apply(lambda x: get_emojis(x)).sum())\n",
        "emojis = {k: v for k,v in sorted(emojis.items(), key=lambda item: item[1], reverse=True)}\n",
        "print('There are {} unique emojis used in this chat.'.format(len(emojis)))\n",
        "print('A total of {} emojis were used.'.format(sum(emojis.values())))\n",
        "\n",
        "print('These are all the emojis used, sorted in reverse ascending order:\\n')\n",
        "for emoji,number in emojis.items():\n",
        "    print(emoji, number)"
      ],
      "execution_count": 760,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 178 unique emojis used in this chat.\n",
            "A total of 9220 emojis were used.\n",
            "These are all the emojis used, sorted in reverse ascending order:\n",
            "\n",
            "üòÇ 7548\n",
            "üò≠ 234\n",
            "‚ôÄ 155\n",
            "ü§¶ 122\n",
            "üèº 102\n",
            "üëã 84\n",
            "üèª 77\n",
            "üòí 59\n",
            "ü•∫ 53\n",
            "üò¥ 52\n",
            "ü§∑ 39\n",
            "ü§™ 38\n",
            "‚ù§ 34\n",
            "üòä 33\n",
            "üòÖ 30\n",
            "üò¢ 29\n",
            "üòû 25\n",
            "üòë 21\n",
            "üëè 19\n",
            "üòì 18\n",
            "‚òÄ 17\n",
            "üò® 16\n",
            "‚ôÇ 15\n",
            "üéâ 15\n",
            "üò§ 13\n",
            "‚ò∫ 13\n",
            "üéä 13\n",
            "üòÅ 12\n",
            "üò¨ 12\n",
            "ü§£ 10\n",
            "üòà 10\n",
            "üëç 10\n",
            "üç™ 9\n",
            "üòñ 8\n",
            "ü§Æ 8\n",
            "üëå 7\n",
            "üòç 7\n",
            "üö¨ 7\n",
            "üòè 7\n",
            "üòÑ 6\n",
            "üí§ 6\n",
            "üòê 6\n",
            "üòî 6\n",
            "ü§é 5\n",
            "üôã 5\n",
            "üíî 5\n",
            "üò™ 4\n",
            "üôÑ 4\n",
            "üò° 4\n",
            "üòé 4\n",
            "üíì 4\n",
            "üôà 4\n",
            "üá∫ 4\n",
            "üá∏ 4\n",
            "üòá 3\n",
            "üòå 3\n",
            "üòö 3\n",
            "üòò 3\n",
            "üê£ 3\n",
            "ü•∞ 3\n",
            "üò† 3\n",
            "‚¨Ü 3\n",
            "‚Äº 3\n",
            "ü•≥ 3\n",
            "üéà 3\n",
            "üç° 2\n",
            "üí∞ 2\n",
            "ü¶† 2\n",
            "üç≥ 2\n",
            "üôÉ 2\n",
            "ü•¥ 2\n",
            "üòâ 2\n",
            "‚ú® 2\n",
            "üôá 2\n",
            "üïõ 2\n",
            "ü¶• 2\n",
            "üçØ 2\n",
            "‚ôæ 2\n",
            "üò∂ 2\n",
            "üò£ 2\n",
            "ü§ù 2\n",
            "ü§≠ 2\n",
            "üíú 2\n",
            "üòÉ 2\n",
            "üò± 2\n",
            "ü§ê 2\n",
            "‚òπ 2\n",
            "üëé 1\n",
            "üßÄ 1\n",
            "üïâ 1\n",
            "üç∞ 1\n",
            "üá® 1\n",
            "üá¶ 1\n",
            "ü¶∑ 1\n",
            "üëê 1\n",
            "üçπ 1\n",
            "üß† 1\n",
            "‚≠ê 1\n",
            "üëÄ 1\n",
            "ü•® 1\n",
            "üêä 1\n",
            "üôÅ 1\n",
            "üòó 1\n",
            "üòô 1\n",
            "üî• 1\n",
            "üßê 1\n",
            "üòÆ 1\n",
            "üå¨ 1\n",
            "‚òÉ 1\n",
            "üôÖ 1\n",
            "üòß 1\n",
            "üí¶ 1\n",
            "üî´ 1\n",
            "‚òé 1\n",
            "üçæ 1\n",
            "üïß 1\n",
            "üïê 1\n",
            "üïú 1\n",
            "üïë 1\n",
            "üïù 1\n",
            "üïí 1\n",
            "üïû 1\n",
            "üïì 1\n",
            "üïü 1\n",
            "üïî 1\n",
            "üï† 1\n",
            "üïï 1\n",
            "üï° 1\n",
            "üïñ 1\n",
            "üï¢ 1\n",
            "üïó 1\n",
            "üï£ 1\n",
            "üïò 1\n",
            "üï§ 1\n",
            "üïô 1\n",
            "üï• 1\n",
            "üïö 1\n",
            "üï¶ 1\n",
            "ü§ó 1\n",
            "üè´ 1\n",
            "üõë 1\n",
            "üöÄ 1\n",
            "üá™ 1\n",
            "üá¨ 1\n",
            "üóº 1\n",
            "ü¶Ñ 1\n",
            "üêí 1\n",
            "üöø 1\n",
            "üåä 1\n",
            "ü§ñ 1\n",
            "üßü 1\n",
            "üê¶ 1\n",
            "üé® 1\n",
            "üó∫ 1\n",
            "üë© 1\n",
            "ü¶∞ 1\n",
            "üçÇ 1\n",
            "‚òï 1\n",
            "‚ùá 1\n",
            "üß∏ 1\n",
            "ü•∂ 1\n",
            "ü¶ã 1\n",
            "ü¶ö 1\n",
            "‚ùó 1\n",
            "ü¶Ö 1\n",
            "üòµ 1\n",
            "üßá 1\n",
            "ü•± 1\n",
            "ü¶ß 1\n",
            "üò´ 1\n",
            "ü§¢ 1\n",
            "ü•ú 1\n",
            "üò© 1\n",
            "üòã 1\n",
            "üé© 1\n",
            "üì∫ 1\n",
            "ü§î 1\n",
            "ü§§ 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LDr82FksfXU"
      },
      "source": [
        "data_as_string = data['Message'].str\n",
        "\n",
        "avg_char = data_as_string.len().mean()\n",
        "characters = data_as_string.len().sum() - 77 #fix \n",
        "\n",
        "doc_lengths = [len(doc) for doc in documents]\n",
        "chars_in_docs = 0\n",
        "for i in doc_lengths:\n",
        "    chars_in_docs += i\n",
        "characters -= chars_in_docs\n",
        "\n",
        "print('A total of {:,} characters were sent'.format(characters))\n",
        "print('Each message sent had an average of {:.2f} characters'.format(avg_char))\n",
        "\n",
        "def get_chars(string):\n",
        "    return ''.join([ch for ch in string if ch not in UNICODE_EMOJI])\n",
        "\n",
        "letters = Counter(data['Message'].apply(lambda x: get_chars(x)).sum())\n",
        "letters = {k: v for k,v in sorted(letters.items(), key=lambda item: item[1], reverse=True)}\n",
        "print('There are {} unique characters used in this chat.'.format(len(letters)))\n",
        "\n",
        "print('These are all the characters used, sorted in reverse ascending order:\\n')\n",
        "for emoji,number in letters.items():\n",
        "    print(emoji, number)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2OKNQw8M4zv"
      },
      "source": [
        "**Person 1 Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsr48H2ed3d1"
      },
      "source": [
        "documents_list_df1 = df1['Message'].apply(lambda x: str(re.findall('.*document omitted', x)))\n",
        "documents_list_df1 = documents_list_df1.to_frame()\n",
        "documents_df1 = documents_list_df1['Message'].unique()\n",
        "documents_df1 = [doc for doc in documents_df1 if len(doc) > 2]\n",
        "documents_df1 = [doc.split(\"\\\\u200\")[0].strip()[2:] for doc in documents_df1]\n",
        "\n",
        "number_of_messages_df1 = df1.shape[0]\n",
        "number_of_pictures_df1 = df1[df1['Message'] == '‚Äéimage omitted'].shape[0]\n",
        "number_of_videos_df1 = df1[df1['Message'] == '‚Äévideo omitted'].shape[0]\n",
        "number_of_stickers_df1 = df1[df1['Message'] == '‚Äésticker omitted'].shape[0]\n",
        "number_of_GIFs_df1 = df1[df1['Message'] == '‚ÄéGIF omitted'].shape[0]\n",
        "number_of_documents_df1 = len(documents_df1)\n",
        "number_of_deleted_messages_df1 = df1[df1['Message'] == '‚ÄéThis message was deleted.'].shape[0] +  df1[df1['Message'] == '‚ÄéYou deleted this message.'].shape[0]\n",
        "\n",
        "number_text_message_df1 = number_of_messages_df1 - number_of_pictures_df1 - number_of_GIFs_df1 - number_of_videos_df1 - number_of_stickers_df1 - number_of_documents_df1\n",
        "\n",
        "print(names[0], 'has sent: {} messages, or {:.2f}% of the total {} messages.'.format(number_of_messages_df1, number_of_messages_df1/number_of_messages*100, data.shape[0]))\n",
        "print('\\n{:,} of which were text messages, or {:.2f}% of the total {} text messages.'.format(number_text_message_df1, number_of_messages_df1/number_text_message*100, number_text_message))\n",
        "print('{} of which were pictures, or {:.2f}% of the total {} pictures.'.format(number_of_pictures_df1, number_of_pictures_df1/number_of_pictures*100, number_of_pictures))\n",
        "\n",
        "print('{} of which were videos, or {:.2f}% of the total {} videos.'.format(number_of_videos_df1, number_of_videos_df1/number_of_videos*100, number_of_videos))\n",
        "print('{} of which were GIFs, or {:.2f}% of the total {} GIFs.'.format(number_of_GIFs_df1, number_of_GIFs_df1/number_of_GIFs*100, number_of_GIFs))\n",
        "print('{} of which were stickers, or {:.2f}% of the total {} stickers.'.format(number_of_stickers_df1, number_of_stickers_df1/number_of_stickers*100, number_of_stickers))\n",
        "print('{} of which were documents, or {:.2f}% of the total {} documents.'.format(number_of_documents_df1, number_of_documents_df1/number_of_documents*100, number_of_documents))\n",
        "print('\\n===The documents were:===')\n",
        "for doc in documents_df1:\n",
        "    print(doc)\n",
        "print(\"\")\n",
        "print(names[0],'deleted {} messages, or {:.2f}% of the total {} deleted messages.'.format(number_of_deleted_messages_df1, number_of_deleted_messages_df1/number_of_deleted_messages * 100, number_of_deleted_messages))\n",
        "\n",
        "number_of_words_df1 = df1['Number of Words'].sum()\n",
        "\n",
        "document_words_df1 = [len(doc.split()) for doc in documents_df1]\n",
        "document_words_df1 = sum(document_words_df1)\n",
        "\n",
        "number_of_words_df1 = number_of_words_df1 - (number_of_pictures_df1*2) - (number_of_GIFs_df1*2) - (number_of_videos_df1*2) - (number_of_stickers_df1*2) - (number_of_documents_df1*2) - document_words_df1\n",
        "\n",
        "print(\"\")\n",
        "print(names[0], 'has sent: {:,} words, or {:.2f}% of the total {} words.'.format(number_of_words_df1, number_of_words_df1/number_of_words*100, number_of_words))\n",
        "print(names[0], 'sends about {:.2f} words per message.'.format(number_of_words_df1/number_text_message_df1))\n",
        "\n",
        "data_as_string_df1 = df1['Message'].str\n",
        "\n",
        "avg_char_df1 = data_as_string_df1.len().mean()\n",
        "characters_df1 = data_as_string_df1.len().sum() - 77 #fix\n",
        "\n",
        "doc_lengths_df1 = [len(doc) for doc in documents_df1]\n",
        "chars_in_docs_df1 = 0\n",
        "for i in doc_lengths_df1:\n",
        "    chars_in_docs_df1 += i\n",
        "characters_df1 -= chars_in_docs_df1\n",
        "\n",
        "print(\"\")\n",
        "print(names[0],'sent a total of {:,} characters, or {:.2f}% of the total {} characters.'.format(characters_df1, characters_df1/characters*100, characters))\n",
        "print('Each message sent had an average of {:.2f} characters'.format(avg_char_df1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQj3jIElBJ2X"
      },
      "source": [
        "most_common_messages_df1 = pd.DataFrame(df1.Message.value_counts())\n",
        "most_common_messages_df1.drop(['‚ÄéThis message was deleted.','‚Äéimage omitted', '‚Äévideo omitted', '‚ÄéGIF omitted', '‚Äésticker omitted'], inplace=True)\n",
        "\n",
        "print(\"\\nThe 25 most common messages for {} were:\".format(names[0]))\n",
        "most_common_messages_df1.head(25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tog3yK-Q2Sbj"
      },
      "source": [
        "words_df1 = Counter()\n",
        "df1['Message'].str.lower().str.split().apply(words_df1.update)\n",
        "\n",
        "print(\"Top 50 most commonly used words for {}:\".format(names[0]))\n",
        "words_df1.most_common(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d88BQf7ZEbZu"
      },
      "source": [
        "emojis_df1 = Counter(df1['Message'].apply(lambda x: get_emojis(x)).sum())\n",
        "emojis_df1 = {k: v for k,v in sorted(emojis_df1.items(), key=lambda item: item[1], reverse=True)}\n",
        "print(names[0],'used {} unique emojis in this chat.'.format(len(emojis_df1)))\n",
        "print(names[0], 'used a total of {} emojis'.format(sum(emojis_df1.values())))\n",
        "\n",
        "print('These are all the emojis used, sorted in reverse ascending order:\\n')\n",
        "for emoji,number in emojis_df1.items():\n",
        "    print(emoji, number)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8JOiGGeM1ua"
      },
      "source": [
        "**Person 2 Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im8PVW8Nga-3"
      },
      "source": [
        "documents_list_df2 = df2['Message'].apply(lambda x: str(re.findall('.*document omitted', x)))\n",
        "documents_list_df2 = documents_list_df2.to_frame()\n",
        "documents_df2 = documents_list_df2['Message'].unique()\n",
        "documents_df2 = [doc for doc in documents_df2 if len(doc) > 2]\n",
        "documents_df2 = [doc.split(\"\\\\u200\")[0].strip()[2:] for doc in documents_df2]\n",
        "\n",
        "number_of_messages_df2 = df2.shape[0]\n",
        "number_of_pictures_df2 = df2[df2['Message'] == '‚Äéimage omitted'].shape[0]\n",
        "number_of_videos_df2 = df2[df2['Message'] == '‚Äévideo omitted'].shape[0]\n",
        "number_of_stickers_df2 = df2[df2['Message'] == '‚Äésticker omitted'].shape[0]\n",
        "number_of_GIFs_df2 = df2[df2['Message'] == '‚ÄéGIF omitted'].shape[0]\n",
        "number_of_documents_df2 = len(documents_df2)\n",
        "number_of_deleted_messages_df2 = df2[df2['Message'] == '‚ÄéThis message was deleted.'].shape[0] + df2[df2['Message'] == '‚ÄéYou deleted this message.'].shape[0]\n",
        "\n",
        "\n",
        "number_text_message_df2 = number_of_messages_df2 - number_of_pictures_df2 - number_of_GIFs_df2 - number_of_videos_df2 - number_of_stickers_df2 - number_of_documents_df2\n",
        "\n",
        "print(names[1], 'has sent: {} messages, or {:.2f}% of the total {} messages.'.format(number_of_messages_df2, number_of_messages_df2/number_of_messages*100, data.shape[0]))\n",
        "print('\\n{:,} of which were text messages, or {:.2f}% of the total {} text messages.'.format(number_text_message_df2, number_of_messages_df2/number_text_message*100, number_text_message))\n",
        "print('{} of which were pictures, or {:.2f}% of the total {} pictures.'.format(number_of_pictures_df2, number_of_pictures_df2/number_of_pictures*100, number_of_pictures))\n",
        "\n",
        "print('{} of which were videos, or {:.2f}% of the total {} videos.'.format(number_of_videos_df2, number_of_videos_df2/number_of_videos*100, number_of_videos))\n",
        "print('{} of which were GIFs, or {:.2f}% of the total {} GIFs.'.format(number_of_GIFs_df2, number_of_GIFs_df2/number_of_GIFs*100, number_of_GIFs))\n",
        "print('{} of which were stickers, or {:.2f}% of the total {} stickers.'.format(number_of_stickers_df2, number_of_stickers_df2/number_of_stickers*100, number_of_stickers))\n",
        "print('{} of which were documents, or {:.2f}% of the total {} documents.'.format(number_of_documents_df2, number_of_documents_df2/number_of_documents*100, number_of_documents))\n",
        "print('\\n===The documents were:===')\n",
        "for doc in documents_df2:\n",
        "    print(doc)\n",
        "print(\"\")\n",
        "print(names[1],'deleted {} messages, or {:.2f}% of the total {} deleted messages.'.format(number_of_deleted_messages_df2, number_of_deleted_messages_df2/number_of_deleted_messages * 100, number_of_deleted_messages))\n",
        "\n",
        "number_of_words_df2 = df2['Number of Words'].sum()\n",
        "\n",
        "document_words_df2 = [len(doc.split()) for doc in documents_df2]\n",
        "document_words_df2 = sum(document_words_df2)\n",
        "\n",
        "number_of_words_df2 = number_of_words_df2 - (number_of_pictures_df2*2) - (number_of_GIFs_df2*2) - (number_of_videos_df2*2) - (number_of_stickers_df2*2) - (number_of_documents_df2*2) - document_words_df2\n",
        "\n",
        "print(\"\")\n",
        "print(names[1], 'has sent: {:,} words, or {:.2f}% of the total {} words.'.format(number_of_words_df2, number_of_words_df2/number_of_words*100, number_of_words))\n",
        "print(names[1], 'sends about {:.2f} words per message.'.format(number_of_words_df2/number_text_message_df2))\n",
        "\n",
        "data_as_string_df2 = df2['Message'].str\n",
        "\n",
        "avg_char_df2 = data_as_string_df2.len().mean()\n",
        "characters_df2 = data_as_string_df2.len().sum() - 77 #fix\n",
        "\n",
        "doc_lengths_df2 = [len(doc) for doc in documents_df2]\n",
        "chars_in_docs_df2 = 0\n",
        "for i in doc_lengths_df2:\n",
        "    chars_in_docs_df2 += i\n",
        "characters_df2 -= chars_in_docs_df2\n",
        "\n",
        "print(\"\")\n",
        "print(names[1],'sent a total of {:,} characters, or {:.2f}% of the total {} characters.'.format(characters_df2, characters_df2/characters*100, characters))\n",
        "print('Each message sent had an average of {:.2f} characters'.format(avg_char_df2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiQ12UkDCOM4"
      },
      "source": [
        "most_common_messages_df2 = pd.DataFrame(df2.Message.value_counts())\n",
        "most_common_messages_df2.drop(['‚ÄéYou deleted this message.','‚Äéimage omitted', '‚Äévideo omitted', '‚ÄéGIF omitted', '‚Äésticker omitted'], inplace=True)\n",
        "\n",
        "print(\"\\nThe 25 most common messages for {} were:\".format(names[1]))\n",
        "most_common_messages_df2.head(25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZav2sPu2w8w"
      },
      "source": [
        "words_df2 = Counter()\n",
        "df2['Message'].str.lower().str.split().apply(words_df2.update)\n",
        "\n",
        "print(\"Top 50 most commonly used words for {}:\".format(names[1]))\n",
        "words_df2.most_common(50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Sd5dO1M9i3"
      },
      "source": [
        "emojis_df2 = Counter(df2['Message'].apply(lambda x: get_emojis(x)).sum())\n",
        "emojis_df2 = {k: v for k,v in sorted(emojis_df2.items(), key=lambda item: item[1], reverse=True)}\n",
        "print(names[1],'used {} unique emojis in this chat.'.format(len(emojis_df2)))\n",
        "print(names[1], 'used a total of {} emojis'.format(sum(emojis_df2.values())))\n",
        "\n",
        "print('These are all the emojis used, sorted in reverse ascending order:\\n')\n",
        "for emoji,number in emojis_df2.items():\n",
        "    print(emoji, number)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDUEehSPwNfu"
      },
      "source": [
        "**VISUALIZATIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV0dCtbG73Gt"
      },
      "source": [
        "data['Message Length'] = data['Message'].str.len()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxJ-On1xwNBW"
      },
      "source": [
        "data['Date'] = [datetime.datetime.strptime(date, \"%d/%m/%y\").date() for date in data['Date']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nq_oCkc3yiX"
      },
      "source": [
        "data['Time'] = [datetime.datetime.strptime(time, \"%I:%M:%S %p\").time() for time in data['Time']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmvo6ycw4rGK"
      },
      "source": [
        "data.groupby(['Date']).size().plot(figsize=(25,6), title='Number Of Messages Each Day')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lWlfUfGQL2r"
      },
      "source": [
        "min_messages_date = data.groupby(['Date']).size().idxmin()\n",
        "min_messages = data.groupby(['Date']).size().min()\n",
        "print('On',min_messages_date,'was the lowest number of messages sent, which was:',min_messages)\n",
        "\n",
        "max_messages_date = data.groupby(['Date']).size().idxmax()\n",
        "max_messages = data.groupby(['Date']).size().max()\n",
        "print('On',max_messages_date,'was the highest number of messages sent, which was:',max_messages)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwSQlZp7F8pX"
      },
      "source": [
        "data.groupby('Date')['Number of Words'].sum().plot(figsize=(25,6), title='Total Number Of Words per Day')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ocQbaxJ56Bb"
      },
      "source": [
        "data.groupby('Date')['Number of Words'].mean().plot(figsize=(25,6), title='Average Number Of Words per Message per Day')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlqYHPWKGIMt"
      },
      "source": [
        "data.groupby('Date')['Message Length'].sum().plot(figsize=(25,6), title='Total Number Of Characters per Day')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnnZzGh88HbD"
      },
      "source": [
        "data.groupby('Date')['Message Length'].mean().plot(figsize=(25,6), title=\"Average Number of Characters per Message per Day\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQhJdzquQYDv"
      },
      "source": [
        "data['Reply Time'] = 0\n",
        "for i in range(len(data)-2):\n",
        "    data['Reply Time'][i+1] = datetime.datetime.combine(data['Date'][i+1],data['Time'][i+1]) - datetime.datetime.combine(data['Date'][i],data['Time'][i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUj0d8ElIA_9"
      },
      "source": [
        "data.groupby(['Date','Author']).count()['Message'].unstack().plot(figsize=(25,6), title=names[0]+' vs '+names[1]+' in number of messages sent per Day')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft_aoyAXMBIZ"
      },
      "source": [
        "data.groupby(['Date','Author'])['Number of Words'].sum().unstack().plot(figsize=(25,6), title=names[0]+' vs '+names[1]+' in number of words sent per Day')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tETMNx88MzuT"
      },
      "source": [
        "data.groupby(['Date','Author'])['Message Length'].mean().unstack().plot(figsize=(25,6), title=names[0]+' vs '+names[1]+' in average message length per Day')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NV7nfSONq7w"
      },
      "source": [
        "data['Reply Time'][0] = data['Reply Time'][1]\n",
        "data['Reply Time'][len(data)-1] = data['Reply Time'][1]\n",
        "data['Reply Time'] = data['Reply Time'].apply(lambda x: x.total_seconds())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mtH1rjzROZm"
      },
      "source": [
        "data['Convo ID'] = (data['Reply Time'] > 1200).cumsum().fillna(0).astype(int) + 1\n",
        "\n",
        "print('There are '+str(data['Convo ID'].max())+' unique conversations.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m01jqnZsTIe1"
      },
      "source": [
        "data.groupby(['Convo ID']).count()['Message'].plot(figsize=(25,6),title=\"Number of messages per conversation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTKUmAEyTxPI"
      },
      "source": [
        "data.groupby(['Convo ID'])['Number of Words'].mean().plot(figsize=(25,6),title=\"Average Number of words per message per conversation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgIKFqaTUxfd"
      },
      "source": [
        "data.groupby(['Convo ID'])['Message Length'].mean().plot(figsize=(25,6),title=\"Average Length of Message per conversation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qsixzJgVxGT"
      },
      "source": [
        "xc = data[data['Convo ID'].between(200,250)]\n",
        "record = xc[xc['Message Length'] == 2887]"
      ],
      "execution_count": 571,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v88M_AoaYGJS"
      },
      "source": [
        "print('This is that super long ass message:')\n",
        "record"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWvSPgSbXiO8"
      },
      "source": [
        "print(\"Your reply to all that effort :(\")\n",
        "xc[xc['Convo ID'] == 230].iloc[0].Message"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdMSLREfvoY8",
        "outputId": "3e8cb4fa-e34a-4229-d024-de0a33a328c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('Average reply time for '+names[0]+' is {:.2f}'.format(data[data['Author'] == names[0]]['Reply Time'].mean()))\n",
        "print('Average reply time for '+names[1]+' is {:.2f}'.format(data[data['Author'] == names[1]]['Reply Time'].mean()))\n",
        "\n",
        "print('\\n^^ This is not representative of the TRUE reply time, as it depends on how quickly replies are sent after a convo is over')"
      ],
      "execution_count": 584,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average reply time for Shaw üê£ is 579.51\n",
            "Average reply time for Preetika Sastry is 493.79\n",
            "\n",
            "^^ This is not representative of the TRUE reply time, as it depends on how quickly replies are sent after a convo is over\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbxJLdllYTvD"
      },
      "source": [
        "data.groupby('Convo ID')['Reply Time'].mean().div(1000).plot(figsize=(25,6), title='Average Reply Time in Seconds per Converation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVsfc6i_vHMw"
      },
      "source": [
        "data.groupby(['Convo ID','Author'])['Reply Time'].mean().div(1000).unstack().plot(figsize=(25,6), title='Average Reply Time in Seconds per Converation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUQdc9kUeAxr"
      },
      "source": [
        "data['Day of Week'] = data.Date.apply(lambda x: x.weekday())\n"
      ],
      "execution_count": 587,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwAHO1j0goK2"
      },
      "source": [
        "data.sort_values(by=['Day of Week']).groupby('Day of Week').count()['Message'].plot(figsize=(25,6), ylabel='Number of Messages', title='Day of Week vs Number of Messages').set_xticklabels(['','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VycZ8hEiAER"
      },
      "source": [
        "data['Time2'] = data.Time.apply(lambda x: x.replace(second=0))\n",
        "data['Time3'] = data.Time.apply(lambda x: x.replace(minute=0, second=0))"
      ],
      "execution_count": 589,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U3IJCgWkbm0"
      },
      "source": [
        "data.groupby(['Time2']).count()['Message'].plot(figsize=(25,6), ylabel='Number of Messages', title='Time of Day (Minutes) vs Number of Messages')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4mD70mZuNfX"
      },
      "source": [
        "data.groupby(['Time3']).count()['Message'].plot(figsize=(25,6), ylabel='Number of Messages', title='Time of Day (Hours) vs Number of Messages')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJD_-kfzHbJs"
      },
      "source": [
        "print(names[0]+' has started {} conversations'.format(data.groupby('Convo ID').first()['Author'].value_counts()[0]))\n",
        "print(names[1]+' has started {} conversations'.format(data.groupby('Convo ID').first()['Author'].value_counts()[1]))\n",
        "print(\"\")\n",
        "print(names[0]+' said \"bye\" last in {} conversations'.format(data.groupby('Convo ID').last()['Author'].value_counts()[0]))\n",
        "print(names[1]+' said \"bye\" last in {} conversations'.format(data.groupby('Convo ID').last()['Author'].value_counts()[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BrvSRyeJ1eE"
      },
      "source": [
        "convo_starts = data.groupby('Convo ID').first()\n",
        "convo_ends = data.groupby('Convo ID').last()\n",
        "convo_dur = pd.concat([convo_starts,convo_ends]).drop_duplicates(keep=False).sort_values(['Date','Time']).reset_index()\n",
        "\n",
        "\n",
        "convo_dur['Convo Time'] = 0\n",
        "for i in range(len(convo_dur)-2):\n",
        "    convo_dur['Convo Time'][i+1] = datetime.datetime.combine(convo_dur['Date'][i+1],convo_dur['Time'][i+1]) - datetime.datetime.combine(convo_dur['Date'][i],convo_dur['Time'][i])\n",
        "convo_dur.drop([len(convo_dur)-1,len(convo_dur)-2], inplace=True)\n",
        "\n",
        "convo_dur = convo_dur.iloc[1::2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOBVpwh-SE4t",
        "outputId": "0f32fa0e-eb28-4419-e193-46fadd65dac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_time = convo_dur['Convo Time'].max().seconds\n",
        "print('Longest time chatted is: {}h {}m {}s'.format(max_time//3600,(max_time%3600)//60, max_time%60))"
      ],
      "execution_count": 726,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longest time chatted is: 4h 19m 57s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEBhimXsXqB7"
      },
      "source": [
        "avg_chat_length = sum(convo_dur['Convo Time'], datetime.timedelta(0)) / len(convo_dur['Convo Time'])\n",
        "print('Average chat length is: {}h {}m {}s'.format(avg_chat_length.seconds//3600,(avg_chat_length.seconds%3600)//60, avg_chat_length.seconds%60))\n",
        "\n",
        "print(\"\\n^^ This is a naive calculation, and not truly representative of the true mean\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TlFs803Mik4"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ngw_IIGPn95"
      },
      "source": [
        "drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}